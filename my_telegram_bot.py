import os
import json
import time
import asyncio
from datetime import datetime
from collections import defaultdict, Counter
import requests
import telebot # ThÆ° viá»‡n pyTelegramBotAPI
from flask import Flask, request, abort # <-- Äáº£m báº£o dÃ²ng nÃ y cÃ³ á»Ÿ Ä‘Ã¢y!

# ==== Cáº¤U HÃŒNH ====
HTTP_API_URL = "https://apisunwin.up.railway.app/api/taixiu"
# TÃªn cÃ¡c file dá»¯ liá»‡u
LICHSU_FILE = "lichsucau.txt"
DUDOAN_FILE = "dudoan.txt"          # File cáº§u VIP Æ°u tiÃªn (AI 1)
AI_FILE = "ai_1-2.txt"              # File cáº§u AI tá»± há»c (AI 2)
PATTERN_COUNT_FILE = "pattern_counter.json" # File Ä‘áº¿m táº§n suáº¥t cho AI 3 vÃ  AI 2
# Tá»‡p nháº­t kÃ½ má»›i Ä‘á»ƒ ghi láº¡i táº¥t cáº£ cÃ¡c dá»± Ä‘oÃ¡n vÃ  káº¿t quáº£ cho viá»‡c há»c nÃ¢ng cao
DULIEU_AI_FILE = "dulieu_ai.json"

# CÃ i Ä‘áº·t thá»i gian vÃ  pattern
CHECK_INTERVAL_SECONDS = 5          # Thá»i gian chá» giá»¯a cÃ¡c láº§n kiá»ƒm tra phiÃªn má»›i
MIN_PATTERN_LENGTH = 4              # Äá»™ dÃ i tá»‘i thiá»ƒu cá»§a pattern
MAX_PATTERN_LENGTH = 15             # Äá»™ dÃ i tá»‘i Ä‘a cá»§a pattern
# NgÆ°á»¡ng há»c cho AI 2
AI_LEARN_THRESHOLD_COUNT = 5
AI_LEARN_THRESHOLD_RATE = 75

# --- MÃ€U Sáº®C CHO CONSOLE ---
RED, GREEN, YELLOW, RESET, BOLD = "\033[91m", "\033[92m", "\033[93m", "\033[0m", "\033[1m"

# ==== BIáº¾N TOÃ€N Cá»¤C ====
lich_su = []
pattern_counter = defaultdict(lambda: {"T": 0, "X": 0})
last_processed_phien = None
cau_dudoan = {}
cau_ai = {}
win_rate_tracker = defaultdict(list)
# Biáº¿n má»›i Ä‘á»ƒ lÆ°u cÃ¡c dá»± Ä‘oÃ¡n Ä‘ang chá» káº¿t quáº£ {phien_id: data}
pending_predictions = {}

bot = None
active_chat_ids = set()

# BIáº¾N CHO LOGIC MD5
md5_giai_doan_counter = 0
md5_analysis_result = "KhÃ¡c"

# ==== CÃC HÃ€M TIá»†N ÃCH & Táº¢I Dá»® LIá»†U ====

def tai_xiu(tong):
    return "T" if tong >= 11 else "X"

def load_data():
    """Táº£i táº¥t cáº£ dá»¯ liá»‡u cáº§n thiáº¿t khi khá»Ÿi Ä‘á»™ng."""
    global lich_su, pattern_counter, cau_dudoan, cau_ai
    # Táº£i lá»‹ch sá»­
    try:
        if os.path.exists(LICHSU_FILE):
            with open(LICHSU_FILE, "r", encoding="utf-8") as f:
                lich_su = [line.strip() for line in f if line.strip() in ['T', 'X']]
            lich_su = lich_su[-MAX_PATTERN_LENGTH:]
    except IOError as e:
        print(f"{RED}Lá»—i khi Ä‘á»c file lá»‹ch sá»­: {e}{RESET}")
        lich_su = []
    # Táº£i bá»™ Ä‘áº¿m pattern
    if os.path.exists(PATTERN_COUNT_FILE):
        try:
            with open(PATTERN_COUNT_FILE, "r", encoding="utf-8") as f:
                pattern_counter = defaultdict(lambda: {"T": 0, "X": 0}, json.load(f))
        except (json.JSONDecodeError, IOError):
            pattern_counter = defaultdict(lambda: {"T": 0, "X": 0})
    # Táº£i cÃ¡c cáº§u Ä‘Ã£ Ä‘á»‹nh nghÄ©a
    cau_dudoan = load_patterns_from_file(DUDOAN_FILE)
    cau_ai = load_patterns_from_file(AI_FILE)
    print(f"{GREEN}ÄÃ£ táº£i {len(cau_dudoan)} pattern VIP vÃ  {len(cau_ai)} pattern AI.{RESET}")

def load_patterns_from_file(filepath):
    """Táº£i cÃ¡c pattern dá»± Ä‘oÃ¡n tá»« má»™t file cá»¥ thá»ƒ."""
    patterns = {}
    if os.path.exists(filepath):
        try:
            with open(filepath, "r", encoding="utf-8") as f:
                for line in f:
                    line = line.strip()
                    if line.startswith("#") or "=>" not in line: continue
                    try:
                        parts = line.split("=>")
                        pattern, prediction_part = parts[0].strip(), parts[1]
                        prediction = prediction_part.split("Dá»± Ä‘oÃ¡n:")[1].strip()[0]
                        if prediction in ["T", "X"]:
                            patterns[pattern] = prediction
                    except IndexError:
                        continue
        except IOError as e:
            print(f"{RED}Lá»—i khi Ä‘á»c file '{filepath}': {e}{RESET}")
    return patterns

def cap_nhat_lich_su_file():
    """LÆ°u lá»‹ch sá»­ cáº§u hiá»‡n táº¡i vÃ o file."""
    try:
        with open(LICHSU_FILE, "w", encoding="utf-8") as f:
            f.write("\n".join(lich_su))
    except IOError as e:
        print(f"{RED}Lá»—i khi ghi lá»‹ch sá»­ vÃ o file: {e}{RESET}")

def save_pattern_counter():
    """LÆ°u bá»™ Ä‘áº¿m táº§n suáº¥t vÃ o file JSON."""
    try:
        with open(PATTERN_COUNT_FILE, "w", encoding="utf-8") as f:
            json.dump(pattern_counter, f, ensure_ascii=False, indent=2)
    except IOError as e:
        print(f"{RED}Lá»—i khi ghi bá»™ Ä‘áº¿m pattern: {e}{RESET}")

def get_data_from_api():
    """Láº¥y dá»¯ liá»‡u phiÃªn má»›i nháº¥t tá»« API."""
    try:
        response = requests.get(HTTP_API_URL, timeout=10)
        response.raise_for_status()
        return response.json()
    except (requests.exceptions.RequestException, json.JSONDecodeError) as e:
        print(f"{YELLOW}Lá»—i API hoáº·c JSON: {e}{RESET}")
        return None

# ==== LOGIC Dá»° ÄOÃN & Há»ŒC Há»I ====

def get_all_predictions(history_str):
    """
    Táº­p há»£p dá»± Ä‘oÃ¡n tá»« táº¥t cáº£ cÃ¡c nguá»“n AI.
    Æ¯u tiÃªn AI 1 (VIP), sau Ä‘Ã³ Ä‘áº¿n AI 2 (Tá»± há»c) vÃ  AI 3 (Thá»‘ng kÃª).
    """
    # AI 1: Dá»±a trÃªn file dudoan.txt (VIP)
    pred_vip = get_prediction_from_source(history_str, cau_dudoan, "AI 1 (VIP)")
    # AI 2: Dá»±a trÃªn file ai_1-2.txt (AI Tá»± Há»c)
    pred_ai_file = get_prediction_from_source(history_str, cau_ai, "AI 2 (Tá»± Há»c)")
    # AI 3: Dá»±a trÃªn xÃ¡c suáº¥t thá»‘ng kÃª
    pred_stat = get_statistical_prediction(history_str)

    return [p for p in [pred_vip, pred_ai_file, pred_stat] if p is not None]

def get_prediction_from_source(history_str, source_patterns, source_name):
    """Láº¥y dá»± Ä‘oÃ¡n tá»« má»™t nguá»“n pattern cá»¥ thá»ƒ, Æ°u tiÃªn cáº§u dÃ i nháº¥t."""
    for length in range(min(len(history_str), MAX_PATTERN_LENGTH), MIN_PATTERN_LENGTH - 1, -1):
        pat = history_str[-length:]
        if pat in source_patterns:
            prediction = source_patterns[pat]
            counts = pattern_counter.get(pat, {"T": 0, "X": 0})
            total = counts['T'] + counts['X']
            accuracy = (counts[prediction] / total * 100) if total > 0 else 100.0
            return {"prediction": prediction, "pattern": pat, "accuracy": accuracy, "source": source_name}
    return None

def get_statistical_prediction(history_str):
    """AI 3: Dá»± Ä‘oÃ¡n dá»±a trÃªn táº§n suáº¥t xuáº¥t hiá»‡n trong quÃ¡ khá»©."""
    for length in range(min(len(history_str), MAX_PATTERN_LENGTH), MIN_PATTERN_LENGTH - 1, -1):
        pat = history_str[-length:]
        if pat in pattern_counter:
            counts = pattern_counter[pat]
            total = counts['T'] + counts['X']
            if total > 0:
                rate_T = (counts['T'] / total) * 100
                rate_X = (counts['X'] / total) * 100
                if rate_T >= AI_LEARN_THRESHOLD_RATE:
                    return {"prediction": "T", "pattern": pat, "accuracy": rate_T, "source": "AI 3 (Thá»‘ng KÃª)"}
                elif rate_X >= AI_LEARN_THRESHOLD_RATE:
                    return {"prediction": "X", "pattern": pat, "accuracy": rate_X, "source": "AI 3 (Thá»‘ng KÃª)"}
    return None

def chot_keo_cuoi_cung(predictions):
    """Tá»•ng há»£p cÃ¡c dá»± Ä‘oÃ¡n Ä‘á»ƒ Ä‘Æ°a ra khuyáº¿n nghá»‹ cuá»‘i cÃ¹ng."""
    if not predictions:
        return {"ket_qua": "Bá» qua", "ly_do": "KhÃ´ng cÃ³ tÃ­n hiá»‡u.", "confidence": "Tháº¥p"}

    votes = Counter(p['prediction'] for p in predictions)
    num_votes = len(predictions)

    if len(votes) == 1:
        final_prediction = list(votes.keys())[0]
        return {"ket_qua": final_prediction, "ly_do": f"Äá»“ng thuáº­n {num_votes}/{num_votes}", "confidence": "Ráº¥t Cao"}

    # Æ¯u tiÃªn AI 1 náº¿u cÃ³ tÃ­n hiá»‡u
    if any(p['source'] == "AI 1 (VIP)" for p in predictions):
        vip_pred = next(p for p in predictions if p['source'] == "AI 1 (VIP)")
        return {"ket_qua": vip_pred['prediction'], "ly_do": f"Æ¯u tiÃªn AI 1 (VIP)", "confidence": "Cao"}

    # Náº¿u khÃ´ng cÃ³ AI 1, chá»n theo sá»‘ Ä‘Ã´ng
    if votes['T'] > votes['X']:
        return {"ket_qua": "T", "ly_do": f"Sá»‘ Ä‘Ã´ng nghiÃªng vá» TÃ i ({votes['T']}/{num_votes})", "confidence": "Trung BÃ¬nh"}
    if votes['X'] > votes['T']:
        return {"ket_qua": "X", "ly_do": f"Sá»‘ Ä‘Ã´ng nghiÃªng vá» Xá»‰u ({votes['X']}/{num_votes})", "confidence": "Trung BÃ¬nh"}

    # Náº¿u xung Ä‘á»™t, chá»n AI cÃ³ accuracy cao nháº¥t
    best_pred = max(predictions, key=lambda p: p['accuracy'])
    return {
        "ket_qua": best_pred['prediction'],
        "ly_do": f"Xung Ä‘á»™t, Æ°u tiÃªn {best_pred['source']} (CX: {best_pred['accuracy']:.1f}%)",
        "confidence": "Trung BÃ¬nh"
    }

def ai_hoc_hoi(history_before_result, actual_result):
    """AI há»c tá»« káº¿t quáº£ thá»±c táº¿ Ä‘á»ƒ cáº­p nháº­t bá»™ Ä‘áº¿m vÃ  tá»± há»c cáº§u má»›i."""
    global md5_analysis_result, cau_dudoan, cau_ai # Äáº£m báº£o cÃ¡c biáº¿n nÃ y Ä‘Æ°á»£c khai bÃ¡o global
    if md5_analysis_result == "GÃ£y":
        print(f"{YELLOW}MD5 'GÃ£y', AI bá» qua viá»‡c há»c phiÃªn nÃ y.{RESET}")
        return

    history_str = "".join(history_before_result)
    for length in range(MIN_PATTERN_LENGTH, min(len(history_str), MAX_PATTERN_LENGTH) + 1):
        pat = history_str[-length:]
        pattern_counter[pat][actual_result] += 1

    potential_pat = history_str[-MIN_PATTERN_LENGTH:]
    if len(potential_pat) == MIN_PATTERN_LENGTH:
        if potential_pat not in cau_dudoan and potential_pat not in cau_ai:
            counts = pattern_counter[potential_pat]
            total = counts['T'] + counts['X']
            if total >= AI_LEARN_THRESHOLD_COUNT:
                rate_T = (counts['T'] / total) * 100
                rate_X = (counts['X'] / total) * 100
                prediction_to_learn = None
                if rate_T >= AI_LEARN_THRESHOLD_RATE: prediction_to_learn = 'T'
                elif rate_X >= AI_LEARN_THRESHOLD_RATE: prediction_to_learn = 'X'

                if prediction_to_learn:
                    try:
                        with open(AI_FILE, "a", encoding="utf-8") as f:
                            f.write(f"\n{potential_pat} => Dá»± Ä‘oÃ¡n: {prediction_to_learn} - Loáº¡i cáº§u: AI Tá»± Há»c")
                        # Táº£i láº¡i cáº§u AI sau khi há»c
                        # global cau_ai # ÄÃ£ khai bÃ¡o á»Ÿ Ä‘áº§u hÃ m rá»“i
                        cau_ai = load_patterns_from_file(AI_FILE)
                        print(f"{GREEN}{BOLD}AI 2 Ä‘Ã£ há»c pattern má»›i: {potential_pat} => {prediction_to_learn}{RESET}")
                    except IOError as e:
                        print(f"{RED}Lá»—i khi ghi cáº§u má»›i cá»§a AI: {e}{RESET}")
    save_pattern_counter()

def log_prediction_data(phien_du_doan, history_str, all_preds, final_choice, actual_result=None, is_win=None):
    """Ghi láº¡i toÃ n bá»™ dá»¯ liá»‡u cá»§a má»™t phiÃªn vÃ o file dulieu_ai.json."""
    log_entry = {
        "phien": phien_du_doan,
        "thoi_gian": datetime.now().isoformat(),
        "lich_su_cau": history_str,
        "tin_hieu_ai": [{"source": p["source"], "prediction": p["prediction"], "pattern": p["pattern"], "accuracy": p["accuracy"]} for p in all_preds],
        "khuyen_nghi": final_choice,
        "ket_qua_thuc_te": actual_result,
        "thang": is_win
    }
    try:
        logs = []
        if os.path.exists(DULIEU_AI_FILE):
            with open(DULIEU_AI_FILE, "r", encoding="utf-8") as f:
                logs = json.load(f)
        
        # TÃ¬m vÃ  cáº­p nháº­t náº¿u log Ä‘Ã£ tá»“n táº¡i, ngÆ°á»£c láº¡i thÃ¬ thÃªm má»›i
        updated = False
        for i, log in enumerate(logs):
            if log["phien"] == phien_du_doan:
                logs[i] = log_entry
                updated = True
                break
        if not updated:
            logs.append(log_entry)

        with open(DULIEU_AI_FILE, "w", encoding="utf-8") as f:
            json.dump(logs, f, ensure_ascii=False, indent=2)
    except (IOError, json.JSONDecodeError) as e:
        print(f"{RED}Lá»—i khi ghi file nháº­t kÃ½ {DULIEU_AI_FILE}: {e}{RESET}")


# ==== LOGIC TELEGRAM ====

async def send_telegram_message(message_text):
    """Gá»­i tin nháº¯n Ä‘áº¿n táº¥t cáº£ cÃ¡c chat_id Ä‘ang hoáº¡t Ä‘á»™ng."""
    # Táº¡o báº£n sao Ä‘á»ƒ trÃ¡nh lá»—i khi sá»­a Ä‘á»•i táº­p há»£p trong lÃºc láº·p
    for chat_id in list(active_chat_ids):
        try:
            await asyncio.to_thread(bot.send_message, chat_id=chat_id, text=message_text, parse_mode='HTML')
        except Exception as e:
            print(f"{RED}Lá»—i khi gá»­i tin nháº¯n tá»›i {chat_id}: {e}{RESET}")
            if "bot was blocked by the user" in str(e):
                active_chat_ids.discard(chat_id)

async def send_prediction_notification(phien_du_doan, predictions, final_choice):
    """Gá»­i thÃ´ng bÃ¡o Dá»° ÄOÃN cho phiÃªn sáº¯p tá»›i."""
    def format_kq(kq):
        return f"<b><font color='green'>TÃ€I</font></b>" if kq == 'T' else f"<b><font color='red'>Xá»ˆU</font></b>"

    message = [f"<b>ğŸ”® Dá»° ÄOÃN CHO PHIÃŠN #{phien_du_doan} ğŸ”®</b>"]
    message.append(f"<b>Lá»‹ch sá»­ cáº§u hiá»‡n táº¡i:</b> <code>{''.join(lich_su)}</code>")
    message.append("â”€" * 25)
    message.append("<b>TÃ­n hiá»‡u tá»« cÃ¡c AI:</b>")

    if predictions:
        for p in predictions:
            message.append(f"  - <b>{p['source']}</b>: {format_kq(p['prediction'])} (Cáº§u: <code>{p['pattern']}</code>, CX: {p['accuracy']:.1f}%)")
    else:
        message.append("  <i>- KhÃ´ng cÃ³ tÃ­n hiá»‡u rÃµ rÃ ng tá»« AI.</i>")

    message.append("â”€" * 25)
    final_kq = final_choice['ket_qua']
    if final_kq == "Bá» qua":
        message.append(f"  â–¶ï¸ <b>KHUYáº¾N NGHá»Š: <font color='orange'>Bá» QUA</font></b>")
    else:
        confidence = final_choice.get('confidence', 'KhÃ´ng xÃ¡c Ä‘á»‹nh')
        conf_color = "green" if confidence == "Ráº¥t Cao" else "orange" if "Cao" in confidence else "red"
        message.append(f"  â–¶ï¸ <b>KHUYáº¾N NGHá»Š: {format_kq(final_kq)}</b> (Äá»™ tin cáº­y: <font color='{conf_color}'>{confidence.upper()}</font>)")
    
    message.append(f"<i>LÃ½ do: {final_choice['ly_do']}</i>")
    await send_telegram_message("\n".join(message))


async def send_result_notification(phien, xx, tong, kq_thucte, prediction_data):
    """Gá»­i thÃ´ng bÃ¡o Káº¾T QUáº¢ cá»§a phiÃªn vá»«a rá»“i vÃ  so sÃ¡nh vá»›i dá»± Ä‘oÃ¡n."""
    final_choice = prediction_data['final_choice']
    is_win = (final_choice['ket_qua'] == kq_thucte) if final_choice['ket_qua'] != "Bá» qua" else None

    # Cáº­p nháº­t tá»· lá»‡ tháº¯ng
    for pred_obj in prediction_data['all_predictions']:
        source_key = pred_obj['source']
        win_rate_tracker[source_key].append(pred_obj['prediction'] == kq_thucte)

    def format_kq(kq):
        return f"<b><font color='green'>TÃ€I</font></b>" if kq == 'T' else f"<b><font color='red'>Xá»ˆU</font></b>"

    title = "âœ… Káº¾T QUáº¢ PHIÃŠN" if is_win is not False else "âŒ Káº¾T QUáº¢ PHIÃŠN"
    message = [f"<b>{title} #{phien}</b>"]
    message.append(f"ğŸ² XÃºc xáº¯c: <b>{xx[0]}-{xx[1]}-{xx[2]}</b> (Tá»•ng: {tong}) => {format_kq(kq_thucte)}")

    if is_win is True:
        message.append(f"ğŸ‰ <b>THáº®NG!</b> - Dá»± Ä‘oÃ¡n <b>{format_kq(final_choice['ket_qua'])}</b> Ä‘Ã£ chÃ­nh xÃ¡c.")
    elif is_win is False:
        message.append(f"ğŸ˜­ <b>THUA!</b> - Dá»± Ä‘oÃ¡n <b>{format_kq(final_choice['ket_qua'])}</b>, káº¿t quáº£ lÃ  <b>{format_kq(kq_thucte)}</b>.")
    else: # Bá» qua
        message.append(f"âšªï¸ <b>Bá» QUA</b> - Bot Ä‘Ã£ khÃ´ng Ä‘Æ°a ra khuyáº¿n nghá»‹ cho phiÃªn nÃ y.")
    
    # ThÃªm tráº¡ng thÃ¡i MD5
    md5_status_color = "red" if md5_analysis_result == "GÃ£y" else "green"
    message.append(f"â›“ï¸ Tráº¡ng thÃ¡i MD5: <font color='{md5_status_color}'>{md5_analysis_result.upper()}</font>")

    await send_telegram_message("\n".join(message))


# ==== VÃ’NG Láº¶P CHÃNH Cá»¦A BOT ====
async def main_bot_loop():
    global last_processed_phien, lich_su

    data = get_data_from_api()
    if not data or not isinstance(data, dict): return

    phien_hien_tai = data.get("Phien")
    if phien_hien_tai is None or (last_processed_phien and phien_hien_tai <= last_processed_phien):
        return

    # === Xá»¬ LÃ Káº¾T QUáº¢ Cá»¦A PHIÃŠN TRÆ¯á»šC ===
    if phien_hien_tai in pending_predictions:
        prediction_data = pending_predictions.pop(phien_hien_tai)
        xx = [data.get("Xuc_xac_1"), data.get("Xuc_xac_2"), data.get("Xuc_xac_3")]
        tong = sum(xx)
        kq_thucte = tai_xiu(tong)

        # Gá»­i thÃ´ng bÃ¡o káº¿t quáº£
        await send_result_notification(phien_hien_tai, xx, tong, kq_thucte, prediction_data)
        
        # Cáº­p nháº­t lá»‹ch sá»­ vÃ  cho AI há»c há»i
        lich_su.append(kq_thucte)
        lich_su = lich_su[-MAX_PATTERN_LENGTH:]
        cap_nhat_lich_su_file()
        
        is_win = (prediction_data['final_choice']['ket_qua'] == kq_thucte) if prediction_data['final_choice']['ket_qua'] != "Bá» qua" else None
        log_prediction_data(phien_hien_tai, prediction_data['history_str'], prediction_data['all_predictions'], prediction_data['final_choice'], kq_thucte, is_win)

        ai_hoc_hoi(prediction_data['history_str'].split(), kq_thucte)

    else:
        # Náº¿u khÃ´ng cÃ³ dá»± Ä‘oÃ¡n chá» xá»­ lÃ½ (vÃ­ dá»¥: láº§n cháº¡y Ä‘áº§u tiÃªn), chá»‰ cáº­p nháº­t lá»‹ch sá»­
        kq_thucte = tai_xiu(data.get("Xuc_xac_1") + data.get("Xuc_xac_2") + data.get("Xuc_xac_3"))
        lich_su.append(kq_thucte)
        lich_su = lich_su[-MAX_PATTERN_LENGTH:]
        cap_nhat_lich_su_file()

    # Cáº­p nháº­t tráº¡ng thÃ¡i MD5 cho phiÃªn tiáº¿p theo
    simulate_md5_analysis()

    # === Dá»° ÄOÃN CHO PHIÃŠN TIáº¾P THEO ===
    phien_tiep_theo = phien_hien_tai + 1
    history_str = "".join(lich_su)

    all_predictions = get_all_predictions(history_str)
    final_choice = chot_keo_cuoi_cung(all_predictions)
    
    # Gá»­i thÃ´ng bÃ¡o dá»± Ä‘oÃ¡n
    await send_prediction_notification(phien_tiep_theo, all_predictions, final_choice)

    # LÆ°u dá»± Ä‘oÃ¡n nÃ y vÃ o danh sÃ¡ch chá»
    pending_predictions[phien_tiep_theo] = {
        "history_str": history_str,
        "all_predictions": all_predictions,
        "final_choice": final_choice
    }
    # Ghi log ban Ä‘áº§u (chÆ°a cÃ³ káº¿t quáº£)
    log_prediction_data(phien_tiep_theo, history_str, all_predictions, final_choice)


    last_processed_phien = phien_hien_tai
    os.system('cls' if os.name == 'nt' else 'clear')
    print(f"{BOLD}ÄÃ£ xá»­ lÃ½ phiÃªn #{phien_hien_tai}, dá»± Ä‘oÃ¡n cho phiÃªn #{phien_tiep_theo}.{RESET}")
    print(f"Lá»‹ch sá»­ cáº§u: {history_str}")
    print(f"Dá»± Ä‘oÃ¡n chá» xá»­ lÃ½: {list(pending_predictions.keys())}")


def simulate_md5_analysis():
    """MÃ´ phá»ng káº¿t quáº£ MD5: 2 GÃ£y -> 1 KhÃ¡c."""
    global md5_giai_doan_counter, md5_analysis_result
    if md5_giai_doan_counter < 2:
        md5_analysis_result = "GÃ£y"
        md5_giai_doan_counter += 1
    else:
        md5_analysis_result = "KhÃ¡c"
        md5_giai_doan_counter = 0

# ==== HÃ€M KHá»I CHáº Y BOT ====
def start_command_handler(message):
    active_chat_ids.add(message.chat.id)
    bot.reply_to(message, "âœ… <b>Bot Ä‘Ã£ Ä‘Æ°á»£c kÃ­ch hoáº¡t!</b>\nTÃ´i sáº½ tá»± Ä‘á»™ng gá»­i dá»± Ä‘oÃ¡n cho cÃ¡c phiÃªn sáº¯p tá»›i.", parse_mode='HTML')
    print(f"{GREEN}ÄÃ£ nháº­n /start tá»« {message.chat.id}{RESET}")

def stop_command_handler(message):
    active_chat_ids.discard(message.chat.id)
    bot.reply_to(message, "âŒ <b>Bot Ä‘Ã£ táº¡m dá»«ng.</b>\nGÃµ /start Ä‘á»ƒ nháº­n láº¡i dá»± Ä‘oÃ¡n.", parse_mode='HTML')
    print(f"{YELLOW}ÄÃ£ nháº­n /stop tá»« {message.chat.id}{RESET}")

# ==== FLASK SERVER Äá»‚ GIá»® Dá»ŠCH Vá»¤ LUÃ”N CHáº Y TRÃŠN RENDER (Náº¾U DÃ™NG WEB SERVICE) ====
app = Flask(__name__)

@app.route('/')
def hello_world():
    # Render sáº½ gá»­i request HTTP Ä‘áº¿n '/' Ä‘á»ƒ kiá»ƒm tra dá»‹ch vá»¥ cÃ³ hoáº¡t Ä‘á»™ng khÃ´ng
    # Chá»‰ cáº§n tráº£ vá» má»™t chuá»—i Ä‘Æ¡n giáº£n Ä‘á»ƒ Render biáº¿t ráº±ng á»©ng dá»¥ng Ä‘ang "sá»‘ng"
    return 'Bot is running and Flask server is active!'

def run_flask_app():
    # Láº¥y port tá»« biáº¿n mÃ´i trÆ°á»ng cá»§a Render (máº·c Ä‘á»‹nh lÃ  10000 náº¿u khÃ´ng tÃ¬m tháº¥y)
    port = int(os.environ.get("PORT", 10000))
    print(f"{YELLOW}Báº¯t Ä‘áº§u Flask server trÃªn cá»•ng {port} Ä‘á»ƒ giá»¯ dá»‹ch vá»¥ luÃ´n cháº¡y...{RESET}")
    # app.run lÃ  blocking, cáº§n cháº¡y trong má»™t thread riÃªng hoáº·c asyncio.to_thread
    app.run(host='0.0.0.0', port=port, debug=False)


async def run_main_loop_periodically():
    while True:
        try:
            if active_chat_ids:
                await main_bot_loop()
        except Exception as e:
            print(f"{RED}Lá»—i trong vÃ²ng láº·p chÃ­nh: {e}{RESET}")
            import traceback
            traceback.print_exc() # In chi tiáº¿t lá»—i Ä‘á»ƒ debug
        await asyncio.sleep(CHECK_INTERVAL_SECONDS)

async def main():
    global bot
    TELEGRAM_BOT_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")
    if not TELEGRAM_BOT_TOKEN:
        print(f"{RED}{BOLD}Lá»–I: Biáº¿n mÃ´i trÆ°á»ng TELEGRAM_BOT_TOKEN chÆ°a Ä‘Æ°á»£c Ä‘áº·t.{RESET}")
        return

    bot = telebot.TeleBot(TELEGRAM_BOT_TOKEN)
    bot.register_message_handler(start_command_handler, commands=['start'])
    bot.register_message_handler(stop_command_handler, commands=['stop'])

    load_data()
    print(f"{BOLD}{GREEN}=== TOOL TX PRO AI V3 (CHá»¦ Äá»˜NG) ===")
    print(f"Bot Ä‘Ã£ sáºµn sÃ ng. Äang chá» lá»‡nh /start...{RESET}")

    # Khá»Ÿi cháº¡y Flask server trong má»™t thread riÃªng Ä‘á»ƒ nÃ³ khÃ´ng block asyncio event loop
    import threading
    flask_thread = threading.Thread(target=run_flask_app)
    flask_thread.daemon = True # Äáº·t thread lÃ  daemon Ä‘á»ƒ nÃ³ tá»± táº¯t khi chÆ°Æ¡ng trÃ¬nh chÃ­nh káº¿t thÃºc
    flask_thread.start()
    
    asyncio.create_task(run_main_loop_periodically())
    
    print(f"{YELLOW}Báº¯t Ä‘áº§u polling Telegram...{RESET}")
    # Cháº¡y polling trong má»™t thread khÃ¡c Ä‘á»ƒ khÃ´ng cháº·n event loop chÃ­nh
    await asyncio.to_thread(bot.polling, none_stop=True, interval=0, timeout=20)

if __name__ == "__main__":
    try:
        os.system('cls' if os.name == 'nt' else 'clear')
        asyncio.run(main())
    except KeyboardInterrupt:
        print(f"\n{RED}{BOLD}ÄÃ£ dá»«ng bot.{RESET}")
    except Exception as e:
        print(f"\n{RED}{BOLD}Lá»—i nghiÃªm trá»ng: {e}{RESET}")
        import traceback
        traceback.print_exc()
